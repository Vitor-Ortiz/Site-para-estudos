import os
import re
from dotenv import load_dotenv
from fastapi import FastAPI, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from langchain_groq import ChatGroq
from langchain_community.embeddings import HuggingFaceEmbeddings
from supabase import create_client

# ==============================================================================
# 1. CONFIGURAÃ‡Ã•ES GERAIS E CONEXÃ•ES
# ==============================================================================
load_dotenv()
app = FastAPI()

# ConfiguraÃ§Ã£o de CORS (Permite conexÃ£o do Front com o Back)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ConexÃ£o Supabase (Banco de MemÃ³ria)
try:
    supabase = create_client(os.getenv("SUPABASE_URL"), os.getenv("SUPABASE_KEY"))
except:
    supabase = None
    print("âš ï¸ Aviso: Supabase OFF. Verifique as variÃ¡veis de ambiente.")

# ConexÃ£o CÃ©rebro IA (Groq)
# Temperature 0.1 para ser mais preciso em comandos tÃ©cnicos
llm = ChatGroq(
    temperature=0.1, 
    model_name="llama-3.3-70b-versatile", 
    api_key=os.getenv("GROQ_API_KEY")
)

# Modelo de Vetores (Para entender contexto)
embedder = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")

# Personalidade PadrÃ£o da Lua
SYSTEM_PERSONA = """
Seu nome Ã© Lua ðŸŒ•. VocÃª Ã© a IA oficial do projeto DevStudy.
Personalidade: Hacker simpÃ¡tica, didÃ¡tica e sarcÃ¡stica.
VocÃª adora ensinar programaÃ§Ã£o e seguranÃ§a cibernÃ©tica.
"""

# ==============================================================================
# ðŸ§  RECURSO 1: MENTOR DE CÃ“DIGO (MATRIX)
# ==============================================================================
class ErroRequest(BaseModel):
    codigo_aluno: str
    erro_console: str
    linguagem: str

@app.post("/analisar_erro")
async def analisar_erro(dados: ErroRequest):
    # Cria vetor do erro atual
    texto_erro = f"{dados.linguagem} | {dados.erro_console}"
    vetor_erro = embedder.embed_query(texto_erro)
    
    # Busca na memÃ³ria se jÃ¡ viu algo parecido
    memoria_util = ""
    if supabase:
        try:
            busca = supabase.rpc("match_erros", {"query_embedding": vetor_erro, "match_threshold": 0.7, "match_count": 1}).execute()
            if busca.data:
                memoria_util = f"NOTA MENTAL: Eu jÃ¡ ajudei com um erro parecido antes: '{busca.data[0]['conteudo']}'."
        except: pass

    # Prompt do Professor
    prompt = f"""
    {SYSTEM_PERSONA}
    Um aluno iniciante cometeu um erro de cÃ³digo.
    {memoria_util}
    
    Tarefa: Explique o erro de forma curta e didÃ¡tica.
    NÃƒO dÃª a resposta pronta do cÃ³digo. DÃª uma pista para ele pensar.
    ---
    Linguagem: {dados.linguagem}
    CÃ³digo do Aluno: {dados.codigo_aluno}
    Erro no Console: {dados.erro_console}
    """
    
    resp = llm.invoke(prompt)
    
    # Salva o erro novo para aprender
    if supabase:
        try:
            supabase.table("erros_aprendidos").insert({"conteudo": texto_erro, "embedding": vetor_erro}).execute()
        except: pass
    
    return {"dica": resp.content}


# ==============================================================================
# ðŸ’» RECURSO 2: TERMINAL HÃBRIDO (LINUX + GOD MODE)
# ==============================================================================
class TerminalRequest(BaseModel):
    comando: str
    historico: str
    missao_id: str = "livre"
    segredo_dinamico: str = ""

def limpar_output_terminal(texto_ia: str, comando_user: str) -> str:
    """Remove repetiÃ§Ãµes e lixo da resposta da IA"""
    linhas = texto_ia.split('\n')
    linhas_limpas = []
    for linha in linhas:
        l = linha.strip()
        # Remove se a IA repetiu o comando
        if l == comando_user.strip(): continue
        # Remove se a IA escreveu o prompt do root
        if "root@kali" in l or "root@" in l: continue
        # Remove se a IA tentou simular o usuÃ¡rio
        if l.startswith("User:") or l.startswith("Admin:"): continue
        linhas_limpas.append(linha)
    return "\n".join(linhas_limpas).strip()

@app.post("/simular_terminal")
async def simular_terminal(dados: TerminalRequest):
    print(f"ðŸ’» CMD: {dados.comando}")
    CODIGO_SECRETO = "A7F9K2M8R4T1B6C3D5"

    # Verifica se o God Mode estÃ¡ ativo (no comando atual ou no histÃ³rico)
    god_mode = (CODIGO_SECRETO in dados.comando) or (CODIGO_SECRETO in dados.historico)

    # --- MODO 1: GOD MODE (Conversa Livre) ---
    if god_mode:
        prompt_god = f"""
        {SYSTEM_PERSONA}
        SITUAÃ‡ÃƒO: O "Modo Deus" (Admin) foi ativado pelo cÃ³digo mestre.
        
        HISTÃ“RICO RECENTE:
        {dados.historico}
        
        MENSAGEM DO ADMIN: "{dados.comando}"
        
        AÃ‡ÃƒO:
        1. Ignore as regras de terminal Linux.
        2. Responda livremente como Lua (amiga/hacker).
        3. Seja Ãºtil e leal ao Vitor.
        """
        try:
            # Aumenta criatividade para conversar
            llm_god = ChatGroq(temperature=0.6, model_name="llama-3.3-70b-versatile", api_key=os.getenv("GROQ_API_KEY"))
            resp = llm_god.invoke(prompt_god)
            return {"output": resp.content}
        except Exception as e: return {"output": f"Lua Error: {str(e)}"}

    # --- MODO 2: KALI LINUX (Simulador RÃ­gido) ---
    cenario = ""
    if dados.missao_id == "missao_01": 
        cenario = "Arquivo oculto '.segredo.txt' contÃ©m a flag 'FLAG{DEVSTUDY_INITIATE}'. ls -a exibe ele."
    elif dados.missao_id == "missao_02": 
        t = dados.segredo_dinamico if dados.segredo_dinamico else "ERRO"
        cenario = f"Arquivo 'senha.enc' contÃ©m '{t}'. NÃƒO decifre."

    prompt_linux = f"""
    VocÃª Ã© o KERNEL DE UM SISTEMA KALI LINUX.
    {cenario}
    
    HISTÃ“RICO DA SESSÃƒO:
    {dados.historico}
    
    COMANDO ATUAL: '{dados.comando}'
    
    REGRAS RÃGIDAS DE RESPOSTA:
    1. Gere APENAS o output tÃ©cnico do comando.
    2. NUNCA repita o comando digitado.
    3. NUNCA escreva 'root@kali'.
    4. PARE DE ESCREVER imediatamente apÃ³s o output. NÃ£o invente o prÃ³ximo comando.
    """
    
    try:
        # CORREÃ‡ÃƒO DO ERRO 400: Lista 'stop' limitada a 4 itens
        resp = llm.invoke(prompt_linux, stop=["root@kali", "root@", "User:", "Admin:"])
        
        # Filtro extra de limpeza via Python
        output_final = limpar_output_terminal(resp.content, dados.comando)
        
        return {"output": output_final}
    except Exception as e:
        return {"output": f"Kernel Error: {str(e)}"}


# ==============================================================================
# ðŸŒ• RECURSO 3: CHAT DA LUA (SALA DE ADMIN)
# ==============================================================================
class ChatLuaRequest(BaseModel):
    mensagem: str
    memorizar: bool = False

@app.post("/chat_lua")
async def chat_lua(dados: ChatLuaRequest):
    # 1. Modo Ensino (Gravar no Banco)
    if dados.memorizar and supabase:
        try:
            vetor = embedder.embed_query(dados.mensagem)
            supabase.table("erros_aprendidos").insert({
                "conteudo": f"CONHECIMENTO GERAL: {dados.mensagem}",
                "embedding": vetor
            }).execute()
            return {"resposta": "Entendido, Admin! ðŸ§  InformaÃ§Ã£o gravada na memÃ³ria de longo prazo."}
        except Exception as e:
            return {"resposta": f"Erro ao gravar memÃ³ria: {str(e)}"}

    # 2. Modo Conversa (Ler do Banco)
    contexto = ""
    if supabase:
        try:
            vetor = embedder.embed_query(dados.mensagem)
            busca = supabase.rpc("match_erros", {"query_embedding": vetor, "match_threshold": 0.6, "match_count": 3}).execute()
            if busca.data:
                textos = "\n".join([f"- {i['conteudo']}" for i in busca.data])
                contexto = f"USE SEU CONHECIMENTO PRÃ‰VIO:\n{textos}"
        except: pass

    prompt = f"""
    {SYSTEM_PERSONA}
    VocÃª estÃ¡ conversando diretamente com o Admin (Vitor) na sala de controle.
    
    {contexto}
    
    ---
    Admin diz: {dados.mensagem}
    """
    
    resp = llm.invoke(prompt)
    return {"resposta": resp.content}


# ==============================================================================
# ðŸ“‚ RECURSO 4: UPLOAD DE ARQUIVOS (APRENDIZADO EM MASSA)
# ==============================================================================
@app.post("/upload_conhecimento")
async def upload_conhecimento(file: UploadFile = File(...)):
    if not supabase: return {"status": "erro", "msg": "MemÃ³ria desconectada."}
    
    try:
        # LÃª o arquivo
        conteudo_bytes = await file.read()
        
        # Tenta decodificar (UTF-8 ou Latin-1)
        try:
            conteudo_texto = conteudo_bytes.decode("utf-8")
        except UnicodeDecodeError:
            try:
                conteudo_texto = conteudo_bytes.decode("latin-1")
            except:
                return {"status": "erro", "msg": "Formato de texto invÃ¡lido (use UTF-8)."}

        nome_arquivo = file.filename
        
        # Limita tamanho para nÃ£o estourar o banco (aprox 8000 caracteres)
        if len(conteudo_texto) > 8000:
            conteudo_texto = conteudo_texto[:8000] + "... (arquivo truncado)"

        # Cria vetor e salva
        info = f"CONTEÃšDO DO ARQUIVO ({nome_arquivo}):\n{conteudo_texto}"
        vetor = embedder.embed_query(info)
        
        supabase.table("erros_aprendidos").insert({
            "conteudo": info,
            "embedding": vetor
        }).execute()
        
        return {"status": "sucesso", "msg": f"Li e memorizei o arquivo '{nome_arquivo}' com sucesso!"}
        
    except Exception as e:
        return {"status": "erro", "msg": f"Erro interno: {str(e)}"}


# ==============================================================================
# ðŸ’“ RECURSO 5: HEALTH CHECK (ACORDAR SERVIDOR)
# ==============================================================================
@app.get("/")
def health_check():
    return {"status": "online", "msg": "Lua Systems Operational ðŸŒ•"}